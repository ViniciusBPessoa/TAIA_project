# Classifica√ß√£o de √Åreas de Conhecimento de Quest√µes do ENEM utilizando computa√ß√£o evolutiva

## Grupo: Apolo Albuquerque, Irlan Andrade, Vin√≠cius Pessoa

Beige and Gray Simplified Professional Portrait University Research Poster.png √© nosso poster.

## üìù Publica√ß√µes Relacionadas
- [Artigo Completo (PDF)](https://www.overleaf.com/read/vgwpqmbqyccw#8b74de)

### An√°lise Inicial da Base de Dados

- Analisamos os [microdados](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem) do ENEM e percebemos que as provas do ENEM digital, criado a partir do ENEM 2020, seguem a estrutura de uma quest√£o por p√°gina em um PDF, o que pode facilitar nosso trabalho. Al√©m disso, o ENEM de 2023 possui um arquivo .txt com todas as quest√µes.
- Assim, teremos 185 quest√µes por prova (5 a mais devido √†s quest√µes de ingl√™s e espanhol) e 4 provas cujas quest√µes ser√£o extra√≠das (ENEM 2020, 2021, 2022 e 2023). Pretendemos extrair e tratar os textos das quest√µes dos PDFs com os conhecimentos j√° adquiridos na disciplina.
- Bibliotecas de Python podem nos ajudar a extrair o texto dos PDFs, organizar a estrutura das quest√µes, remover stopwords, fazer embeddings, separar os dados de treino e teste, e ent√£o treinar um modelo para a classifica√ß√£o das quest√µes em:
  
  - Ci√™ncias Humanas
  - Ci√™ncias da Natureza
  - Linguagens
  - Matem√°tica
  
- No total, pretendemos extrair 740 quest√µes divididas da seguinte forma: 180 de Ci√™ncias Humanas, Ci√™ncias da Natureza e Matem√°tica, cada. Linguagens: 200 quest√µes, resultando em uma base de dados relativamente balanceada.

### Explora√ß√£o e Tratamento dos Dados

- A explora√ß√£o dos dados foi feita utilizando a biblioteca PyPDF2, durante este processo foi encontradas algumas anomalias nos PDFs das provas de 2020 a 2022, como exemplos: algumas alternativas "A" estavam coladas aos enunciados (sem um /n), nas provas de 2021 e 2022 a √°rea de conhecimento era lida, por exemplo, "Ci√™ncias da Natureza e suas T ecnologias".
  
- A melhor alternativa encontrada de importa√ß√£o dos textos dos PDFs foi utilizando um regex para splitar os blocos de quest√£o que sempre iniciavam com "Quest√£o - XXX..." e, dado que a maioria das quest√µes continha suas alternativas em uma linha, as ultimas 5 linhas de cada bloco foram consideradas como sendo as alternativas. Inicialmente duas bases dados foram criadas: uma com os enunciados e alternativas separadas e outra com o texto deles juntos em uma s√≥ coluna.
  
- A prova de 2023 tinha um arquivo .txt com suas quest√µes, o que, relativamente, facilitou o trabalho. Para o caso dessa prova, as quest√µes sempre inciavam com "QUEST√ÉO XXX".
  
- Tendo em vista que as provas de Linguagens (Ingl√™s e Espanhol) vieram em PDFs separados, foi-se importadas quest√µes duplicadas, o que foi resolvido.

- C√©lulas vazias s√£o poss√≠veis imagens, foi adicionado "poss√≠vel imagem" como padr√£o para partes sem preenchimento nos CSVs. Isso tamb√©m ajuda na parte de pr√©-processamento de texto.

- O pr√©-processamento foi feito aplicando algumas como deixar tudo min√∫sculo, remover pontua√ß√µes, fazer tokeniza√ß√£o, fazer Stemming, remover stopwords e palavras pequenas mantendo termos importantes. Tamb√©m foi considerado que algumas alternativas de matem√°tica podem contem somente um d√≠gito (n√∫mero).

- No total temos 4 base de dados no caminho `Explora√ß√£o e Tratamento dos Dados/CSV`, todas com 753 elementos:

  - `alternativas_separadas.csv`: uma base **sem** pr√©-processamento contendo as colunas 'Ano', 'Enunciado', 'Alternativa_A', 'Alternativa_B', 'Alternativa_C', 'Alternativa_D', 'Alternativa_E' e 'Area_de_Conhecimento';
  - `tudo_junto.csv`: uma base **sem** pr√©-processamento contendo as colunas 'Ano', 'Enunciado_Alternativas' e 'Area_de_Conhecimento';
  - `alternativas_separadas_pp.csv`: uma base **com** pr√©-processamento contendo as colunas 'Ano', 'Enunciado', 'Alternativa_A', 'Alternativa_B', 'Alternativa_C', 'Alternativa_D', 'Alternativa_E' e 'Area_de_Conhecimento';
  - `tudo_junto_pp.csv`: uma base **com** pr√©-processamento contendo as colunas 'Ano', 'Enunciado_Alternativas' e 'Area_de_Conhecimento';

  A grande diferen√ßa entre as bases `alternativas_separadas` e `tudo_junto`, para al√©m da jun√ß√£o de enunciado e alternativas, √© o processo no qual foi adicionado "poss√≠vel imagem" nas c√©lulas vazias das alternativas da base `alternativas_separadas`.
  
- Na pasta `Explora√ß√£o e Tratamento dos Dados` est√£o contidos os diret√≥rios `CSV`: que aloca as bases dados j√° constru√≠das, `Provas`: que cont√©m os arquivos PDF e txt das provas e `data.ipynb`: c√≥digo Python onde foram realizados os experimentos e tratamentos dos dados.

### Explora√ß√£o a An√°lise dos Dados

- √â necess√°rio verificar como esta realizada a distribui√ß√£o de quest√µes dentro de nossa base de dados, tendo em vista que caso a mesma estive-se desbalanceada mais tratamentos deveriam ser feitos, a distribui√ß√£o final foi de (**27.40%** em Linguagens, **22.73%** em Ci√™ncias Humanas, **24.24%** em Ci√™ncias da Natureza, **25,63%** em Matem√°tica), logo satisfatoriamente **balanceada**.
- Outro ponto que necessita ser abordado √© o de como se comportam as falhas dentro do dataste, e conde as mesmas se agrupam (Para uma vis√£o mais bem elaborada quanto a esse ponto recomendo a leitura do relat√≥rio ao fim desse documento), onde √© not√°vel a aus√™ncia de falhas nos enunciados mas a domin√¢ncia dos mesmos quase que exclusivamente em matem√°tica e natureza, essa descoberta nus leva a buscar ate conde interferem essas em compara√ß√£o com a sele√ß√£o e utiliza√ß√£o unicamente do enunciado(que esta completo).
 - Tudo isso pode ser encontrado na pasta `Analitcs` no arquivo `analise_dataset.ipynb`.

### Modelos Feij√£o com Arroz

- Com a inten√ß√£o de comparar com algoritmos de Aprendizagem por Refor√ßo, foram treinados 3 modelos cl√°ssicos de classifica√ß√£o utilizando TF-IDF para vetoriza√ß√£o que incluem:
  
  - **Naive Bayes**: Foi utilizado o modelo `MultinomialNB` em sua forma padr√£o, entretanto, foi adicionado o par√¢metro `sublinear_tf=True` no TfidfVectorizer que o deixa mais sens√≠vel a termos menos frequentes mas potencialmente mais significativos, que, no geral, melhorou sua acur√°cia nos datasets;
  - **Logistic Regression**: Foi utilizado o modelo `LogisticRegression` com os par√¢metros `multi_class='multinomial'` e `solver='lbfgs'`, o `solver='lbfgs'` especifica que o modelo de regress√£o log√≠stica usar√° o algoritmo L-BFGS para otimizar os coeficientes. Aqui tamb√©m inclu√≠ o par√¢metro `sublinear_tf=True` no TfidfVectorizer;
  - **Random Forest**: Foi utilizado o modelo `RandomForestClassifier` com os par√¢metros `n_estimators=200` e `random_state=3`, `n_estimators=200` determina a quantidade de √°rvores na floresta e a quantidade 200 foi definida ap√≥s alguns testes: 100 √© a quantidade padr√£o, 200 foi o m√°ximo encontrado para a melhor acur√°cia do modelo. Mais de 200 demandam mais poder computacional, refinam o modelo mas n√£o melhoram a acur√°cia.

  Todos os modelos foram treinados com um test split de 80/20 (80% para treino e 20% para teste).

- Abaixo segue tabela comparativa com as acur√°cias para cada dataset de cada modelo e a m√©dia das acur√°cias de cada dataset:
  
  | Dataset                 |   Naive Bayes |   Logistic Regression |   Random Forest |   M√©dia de Acur√°cia |
  |:---|---:|---:|---:|---:|
  | alternativas_separadas   |      0.847682 |              0.860927 |        0.781457 |            0.830022 |
  | alternativas_separadas_pp|      0.874172 |              0.894040 |        0.860927 |            0.876380 |
  | tudo_junto               |      0.854305 |              0.854305 |        0.761589 |            0.823400 |
  | tudo_junto_pp            |      0.894040 |              0.894040 |        0.827815 |            0.871965 |

  De imediato, pode-se observar que as bases de dados pr√©-processadas tiveram acur√°cias melhores das que n√£o tiveram esse processo.

- Na pasta `Modelos Feij√£o com Arroz` est√£o contidos os diret√≥rios `CSV`: que aloca as bases dados e `main.ipynb`: c√≥digo Python onde foram realizados os treinamentos dos modelos.

### Metodologia de Utiliza√ß√£o do Google Gemini

- Utiliza√ß√£o do Gemini foi feita como uma base comparativa para verificar a efic√°cia de modelos generativos no mercado em compara√ß√£o com os cl√°ssicos na atividade de classifica√ß√£o textual.
- Inicialmente foi gerada uma chave para acesso a API (Aplication Programing Interface), chave essa que esta contida em `Analitcs` e `.env`.
- Com a chave em m√£o inicializamos a engenharia de  prompt  para  para realizarmos as requisi√ß√µes solicitando as respostas.
- Para esse experimento utilizamos o modelo `gemini 1.5-flash` dado o seu custo beneficio.
- O c√≥digo que realiza a requisi√ß√£o pode ser encontrado em `Analitcs` e `gemini_data.ipynb` e para carregar a base de dados que pretende enviar ao gemini basta alterar o a linha de c√≥digo  *data = pd.read_csv(r'CSV\alternativas_separadas.csv')* para garantir que o nome do arquivo √© o desejado.
- Todas as respostas fornecidas pelo modelo foram realizadas no sequente padr√£o como foi solicitado no prompt '0 \n'.  onde de 0 a 3 representam nossas poss√≠veis classes al√©m de necessitar de convers√£o para a forma inteira previamente a analise.

### Analise de dados do Google Gemini

- J√° dentro de `Analitcs` e `gemini_analitcs.ipynb` √© poss√≠vel observar como ficaram distribu√≠das as respostas do google gemini em acur√°cia geral, por √°rea  e matriz de difus√£o.
- Utilizando a biblioteca *pickle* salvei as listas j√° convertidas para facilitar a analise. (Caso queira acessar tanto os dados de unicamente o enunciado quanto enunciado e alternativas basta  alterar o nome de **with open('lista_1a1.pkl', 'rb')** as file: contendo tudo junto para **with open('lista_enum_1a1.pkl', 'rb')** as file.
- A analise gr√°fica recomendo a leitura do relat√≥rio escrito ao fim desse documento, mesmo assim no fim fica n√≠tida a efici√™ncia geral do modelo 81%, como tamb√©m atrav√©s da matriz de confus√£o √© not√°vel a confus√£o realizada pelo modelo ao classificar varias vezes uma pergunta de linguagens como ci√™ncias humanas.

### Analise de dados dos modelos de redes neurais

- Utilizamos primeiramente **Aprendizagem Supervisionada**:
	- O treinamento supervisionado de redes neurais √© basicamente ensinar uma rede com exemplos onde voc√™ j√° sabe a resposta. Voc√™ d√° √† rede dados com as respostas certas e ela aprende a ajustar seus par√¢metros para que, quando v√™ novos dados, possa prever a resposta correta. Tentando sempre minimizar o erro entre o que a rede prev√™ e o que deveria prever, e isso √© feito ajustando os par√¢metros da rede usando algoritmos espec√≠ficos.
	- 
- **Redes Neurais Densas**: Estas redes possuem camadas onde cada neur√¥nio est√° conectado a todos os neur√¥nios da camada anterior. S√£o amplamente usadas para tarefas de classifica√ß√£o e regress√£o. No treinamento supervisionado, voc√™ fornece dados rotulados para a rede aprender a mapear entradas para sa√≠das desejadas.
    
- **Redes Neurais Recorrentes (RNNs)**: S√£o projetadas para lidar com dados sequenciais, como s√©ries temporais ou texto. Elas t√™m conex√µes que permitem a propaga√ß√£o de informa√ß√µes ao longo do tempo. No treinamento supervisionado, voc√™ fornece sequ√™ncias de dados e os r√≥tulos associados para que a rede aprenda padr√µes temporais e contextuais.

Toda essa analise gr√°fica pode ser encontrada em `Analitcs` e `Modelos_maiores.ipynb`.

### Rascunho do Relat√≥rio em Formato de Artigo

Link no Overleaf: https://www.overleaf.com/read/frvhftjgchkr#6b841c
