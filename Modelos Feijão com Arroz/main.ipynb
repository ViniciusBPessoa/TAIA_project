{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos \"feijão com arroz\" utilizando TF-IDF para vetorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo Naive Bayes\n",
    "Aqui foi adicionado o parâmetro \"sublinear_tf=True\" no TfidfVectorizer que o deixa mais sensível a termos menos frequentes mas potencialmente mais significativos, que, no geral, melhorou sua acurácia nos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do modelo no conjunto alternativas_separadas.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.95      0.66      0.78        32\n",
      "          Linguagens       0.88      0.70      0.78        30\n",
      "    Ciências Humanas       0.78      1.00      0.88        47\n",
      "Ciências da Natureza       0.87      0.93      0.90        42\n",
      "\n",
      "            accuracy                           0.85       151\n",
      "           macro avg       0.87      0.82      0.83       151\n",
      "        weighted avg       0.86      0.85      0.84       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto alternativas_separadas_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.89      0.75      0.81        32\n",
      "          Linguagens       0.86      0.80      0.83        30\n",
      "    Ciências Humanas       0.87      1.00      0.93        47\n",
      "Ciências da Natureza       0.88      0.88      0.88        42\n",
      "\n",
      "            accuracy                           0.87       151\n",
      "           macro avg       0.87      0.86      0.86       151\n",
      "        weighted avg       0.87      0.87      0.87       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.94      0.47      0.62        32\n",
      "          Linguagens       0.93      0.93      0.93        30\n",
      "    Ciências Humanas       0.72      1.00      0.84        47\n",
      "Ciências da Natureza       0.97      0.93      0.95        42\n",
      "\n",
      "            accuracy                           0.85       151\n",
      "           macro avg       0.89      0.83      0.84       151\n",
      "        weighted avg       0.88      0.85      0.84       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.91      0.62      0.74        32\n",
      "          Linguagens       0.97      0.97      0.97        30\n",
      "    Ciências Humanas       0.81      1.00      0.90        47\n",
      "Ciências da Natureza       0.95      0.93      0.94        42\n",
      "\n",
      "            accuracy                           0.89       151\n",
      "           macro avg       0.91      0.88      0.89       151\n",
      "        weighted avg       0.90      0.89      0.89       151\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_model(csv_path):\n",
    "  df_train = pd.read_csv(\"CSV/\" + csv_path)\n",
    "  df_train = df_train.fillna('')\n",
    "\n",
    "  if \"alternativas_separadas\" in csv_path:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado'])\n",
    "\n",
    "    # Vetoriza as colunas de alternativa\n",
    "    alternative_columns = ['Alternativa_A', 'Alternativa_B', 'Alternativa_C', 'Alternativa_D', 'Alternativa_E']\n",
    "    for col in alternative_columns:\n",
    "        X_train_text += vectorizer.transform(df_train[col])\n",
    "\n",
    "  else:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado_Alternativas'])\n",
    "\n",
    "  # Divide os dados em conjunto de treinamento e teste\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_train_text, df_train['Area_de_Conhecimento'], test_size=0.2, random_state=3)\n",
    "\n",
    "  # Treinamento do modelo\n",
    "  model = MultinomialNB()\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predição no conjunto de teste\n",
    "  y_pred_train = model.predict(X_test)\n",
    "\n",
    "  # Avaliação do modelo\n",
    "  print(f\"Avaliação do modelo no conjunto {csv_path}:\\n\")\n",
    "  print(classification_report(y_test, y_pred_train, target_names=['Matemática', 'Linguagens', 'Ciências Humanas', 'Ciências da Natureza']))\n",
    "  print(\"-\"*62)\n",
    "\n",
    "  return classification_report(y_test, y_pred_train, output_dict=True)['accuracy']\n",
    "\n",
    "accuracies_naive_bayes = []\n",
    "for filename in os.listdir('CSV'):\n",
    "   accuracies_naive_bayes.append(train_model(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo Logistic Regression\n",
    "Aqui foi adicionado o parâmetro \"sublinear_tf=True\" no TfidfVectorizer que o deixa mais sensível a termos menos frequentes mas potencialmente mais significativos, que, no geral, melhorou sua acurácia nos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do modelo no conjunto alternativas_separadas.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.89      0.78      0.83        32\n",
      "          Linguagens       0.76      0.83      0.79        30\n",
      "    Ciências Humanas       0.90      0.91      0.91        47\n",
      "Ciências da Natureza       0.88      0.88      0.88        42\n",
      "\n",
      "            accuracy                           0.86       151\n",
      "           macro avg       0.86      0.85      0.85       151\n",
      "        weighted avg       0.86      0.86      0.86       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto alternativas_separadas_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.81      0.81      0.81        32\n",
      "          Linguagens       0.87      0.90      0.89        30\n",
      "    Ciências Humanas       0.94      0.94      0.94        47\n",
      "Ciências da Natureza       0.93      0.90      0.92        42\n",
      "\n",
      "            accuracy                           0.89       151\n",
      "           macro avg       0.89      0.89      0.89       151\n",
      "        weighted avg       0.89      0.89      0.89       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.83      0.62      0.71        32\n",
      "          Linguagens       0.83      0.97      0.89        30\n",
      "    Ciências Humanas       0.80      0.96      0.87        47\n",
      "Ciências da Natureza       0.97      0.83      0.90        42\n",
      "\n",
      "            accuracy                           0.85       151\n",
      "           macro avg       0.86      0.85      0.84       151\n",
      "        weighted avg       0.86      0.85      0.85       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.81      0.69      0.75        32\n",
      "          Linguagens       0.97      0.97      0.97        30\n",
      "    Ciências Humanas       0.85      0.94      0.89        47\n",
      "Ciências da Natureza       0.95      0.95      0.95        42\n",
      "\n",
      "            accuracy                           0.89       151\n",
      "           macro avg       0.90      0.89      0.89       151\n",
      "        weighted avg       0.89      0.89      0.89       151\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_model(csv_path):\n",
    "  df_train = pd.read_csv(\"CSV/\" + csv_path)\n",
    "  df_train = df_train.fillna('')\n",
    "\n",
    "  if \"alternativas_separadas\" in csv_path:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado'])\n",
    "\n",
    "    # Vetoriza as colunas de alternativa\n",
    "    alternative_columns = ['Alternativa_A', 'Alternativa_B', 'Alternativa_C', 'Alternativa_D', 'Alternativa_E']\n",
    "    for col in alternative_columns:\n",
    "        X_train_text += vectorizer.transform(df_train[col])\n",
    "\n",
    "  else:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado_Alternativas'])\n",
    "\n",
    "  # Divide os dados em conjunto de treinamento e teste\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_train_text, df_train['Area_de_Conhecimento'], test_size=0.2, random_state=3)\n",
    "\n",
    "  # Treinamento do modelo\n",
    "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predição no conjunto de teste\n",
    "  y_pred_train = model.predict(X_test)\n",
    "\n",
    "  # Avaliação do modelo\n",
    "  print(f\"Avaliação do modelo no conjunto {csv_path}:\\n\")\n",
    "  print(classification_report(y_test, y_pred_train, target_names=['Matemática', 'Linguagens', 'Ciências Humanas', 'Ciências da Natureza']))\n",
    "  print(\"-\"*62)\n",
    "\n",
    "  return classification_report(y_test, y_pred_train, output_dict=True)['accuracy']\n",
    "\n",
    "accuracies_logistic_regression = []\n",
    "for filename in os.listdir('CSV'):\n",
    "   accuracies_logistic_regression.append(train_model(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do modelo no conjunto alternativas_separadas.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.81      0.53      0.64        32\n",
      "          Linguagens       0.69      0.83      0.76        30\n",
      "    Ciências Humanas       0.76      0.89      0.82        47\n",
      "Ciências da Natureza       0.87      0.81      0.84        42\n",
      "\n",
      "            accuracy                           0.78       151\n",
      "           macro avg       0.78      0.77      0.77       151\n",
      "        weighted avg       0.79      0.78      0.78       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto alternativas_separadas_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.79      0.69      0.73        32\n",
      "          Linguagens       0.84      0.90      0.87        30\n",
      "    Ciências Humanas       0.86      0.89      0.88        47\n",
      "Ciências da Natureza       0.93      0.93      0.93        42\n",
      "\n",
      "            accuracy                           0.86       151\n",
      "           macro avg       0.85      0.85      0.85       151\n",
      "        weighted avg       0.86      0.86      0.86       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.90      0.59      0.72        32\n",
      "          Linguagens       0.60      0.83      0.69        30\n",
      "    Ciências Humanas       0.79      0.96      0.87        47\n",
      "Ciências da Natureza       0.84      0.62      0.71        42\n",
      "\n",
      "            accuracy                           0.76       151\n",
      "           macro avg       0.78      0.75      0.75       151\n",
      "        weighted avg       0.79      0.76      0.76       151\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Avaliação do modelo no conjunto tudo_junto_pp.csv:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Matemática       0.91      0.66      0.76        32\n",
      "          Linguagens       0.72      0.87      0.79        30\n",
      "    Ciências Humanas       0.82      0.96      0.88        47\n",
      "Ciências da Natureza       0.89      0.79      0.84        42\n",
      "\n",
      "            accuracy                           0.83       151\n",
      "           macro avg       0.84      0.82      0.82       151\n",
      "        weighted avg       0.84      0.83      0.83       151\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_model(csv_path):\n",
    "  df_train = pd.read_csv(\"CSV/\" + csv_path)\n",
    "  df_train = df_train.fillna('')\n",
    "\n",
    "  if \"alternativas_separadas\" in csv_path:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado'])\n",
    "\n",
    "    # Vetoriza as colunas de alternativa\n",
    "    alternative_columns = ['Alternativa_A', 'Alternativa_B', 'Alternativa_C', 'Alternativa_D', 'Alternativa_E']\n",
    "    for col in alternative_columns:\n",
    "        X_train_text += vectorizer.transform(df_train[col])\n",
    "\n",
    "  else:\n",
    "    # Vetorização do texto usando TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_text = vectorizer.fit_transform(df_train['Enunciado_Alternativas'])\n",
    "\n",
    "  # Divide os dados em conjunto de treinamento e teste\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_train_text, df_train['Area_de_Conhecimento'], test_size=0.2, random_state=3)\n",
    "\n",
    "  # Treinamento do modelo\n",
    "  model = RandomForestClassifier(n_estimators=200, random_state=3)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predição no conjunto de teste\n",
    "  y_pred_train = model.predict(X_test)\n",
    "\n",
    "  # Avaliação do modelo\n",
    "  print(f\"Avaliação do modelo no conjunto {csv_path}:\\n\")\n",
    "  print(classification_report(y_test, y_pred_train, target_names=['Matemática', 'Linguagens', 'Ciências Humanas', 'Ciências da Natureza']))\n",
    "  print(\"-\"*62)\n",
    "\n",
    "  return classification_report(y_test, y_pred_train, output_dict=True)['accuracy']\n",
    "\n",
    "accuracies_random_forest = []\n",
    "for filename in os.listdir('CSV'):\n",
    "   accuracies_random_forest.append(train_model(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando acurácias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════════════╤═══════════════╤═══════════════════════╤═════════════════╤═════════════════════╕\n",
      "│ Dataset                   │   Naive Bayes │   Logistic Regression │   Random Forest │   Média de Acurácia │\n",
      "╞═══════════════════════════╪═══════════════╪═══════════════════════╪═════════════════╪═════════════════════╡\n",
      "│ alternativas_separadas    │      0.847682 │              0.860927 │        0.781457 │            0.830022 │\n",
      "├───────────────────────────┼───────────────┼───────────────────────┼─────────────────┼─────────────────────┤\n",
      "│ alternativas_separadas_pp │      0.874172 │              0.89404  │        0.860927 │            0.87638  │\n",
      "├───────────────────────────┼───────────────┼───────────────────────┼─────────────────┼─────────────────────┤\n",
      "│ tudo_junto                │      0.854305 │              0.854305 │        0.761589 │            0.8234   │\n",
      "├───────────────────────────┼───────────────┼───────────────────────┼─────────────────┼─────────────────────┤\n",
      "│ tudo_junto_pp             │      0.89404  │              0.89404  │        0.827815 │            0.871965 │\n",
      "╘═══════════════════════════╧═══════════════╧═══════════════════════╧═════════════════╧═════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "datasets = ['alternativas_separadas', 'alternativas_separadas_pp', 'tudo_junto', 'tudo_junto_pp']\n",
    "\n",
    "df_accuracies = pd.DataFrame({\n",
    "    'Dataset': datasets,\n",
    "    'Naive Bayes': accuracies_naive_bayes,\n",
    "    'Logistic Regression': accuracies_logistic_regression,\n",
    "    'Random Forest': accuracies_random_forest\n",
    "})\n",
    "\n",
    "df_accuracies['Média de Acurácia'] = df_accuracies.mean(axis=1, numeric_only=True)\n",
    "\n",
    "print(tabulate(df_accuracies, headers='keys', tablefmt='fancy_grid', showindex=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
